{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/37stu37/FFE/blob/master/FFE_network_one_file_run.ipynb",
      "authorship_tag": "ABX9TyODm18pBcfhG91F828eWnYD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/37stu37/FFE/blob/master/FFE_numba_Dask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGCGL2eCzyEv",
        "colab_type": "code",
        "outputId": "d3c277cd-99aa-48aa-d362-c58b4885d8b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time \n",
        "%%capture\n",
        "!apt update\n",
        "!apt upgrade\n",
        "!apt install gdal-bin python-gdal python3-gdal \n",
        "# Install rtree - Geopandas requirment\n",
        "!apt install python3-rtree \n",
        "# Install Geopandas\n",
        "!pip install git+git://github.com/geopandas/geopandas.git\n",
        "# Install descartes - Geopandas requirment\n",
        "!pip install descartes \n",
        "!pip install memory_profiler"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4.18 s, sys: 734 ms, total: 4.91 s\n",
            "Wall time: 28.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PipQ4HNTjKW",
        "colab_type": "code",
        "outputId": "01d79b5e-c651-4a21-ab4f-a38429de283d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "%tensorflow_version 2.x\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr0PZxCvmWCl",
        "colab_type": "code",
        "outputId": "a394de98-5b74-404d-e9f7-e6f200ec054d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%%time\n",
        "import datetime\n",
        "import glob\n",
        "import shutil\n",
        "from math import sqrt\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import bokeh\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from scipy.spatial import distance\n",
        "from shapely.geometry import box\n",
        "from shapely.geometry import shape\n",
        "from shapely.geometry import Point\n",
        "import networkx as nx\n",
        "from sys import getsizeof\n",
        "from numba import jit\n",
        "import dask.dataframe as dd\n",
        "import dask.array as da\n",
        "import dask\n",
        "from dask.distributed import Client\n",
        "from dask.diagnostics import ProgressBar\n",
        "%matplotlib inline\n",
        "%load_ext memory_profiler\n",
        "\n",
        "pd.options.mode.chained_assignment = None  # default='warn'"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The memory_profiler extension is already loaded. To reload it, use:\n",
            "  %reload_ext memory_profiler\n",
            "CPU times: user 13.4 ms, sys: 2.21 ms, total: 15.6 ms\n",
            "Wall time: 15 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz4lyV9f3Sny",
        "colab_type": "code",
        "outputId": "b38f134e-a7bc-471f-b710-fca8ff2a986a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "source": [
        "client = Client(processes=False)\n",
        "client"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/distributed/bokeh/core.py:57: UserWarning: \n",
            "Failed to start diagnostics server on port 8787. [Errno 99] Cannot assign requested address\n",
            "  warnings.warn('\\n' + msg)\n",
            "/usr/local/lib/python3.6/dist-packages/distributed/deploy/local.py:197: UserWarning: \n",
            "Could not launch service 'bokeh' on port 8787. Got the following message:\n",
            "\n",
            "[Errno 99] Cannot assign requested address\n",
            "  self.scheduler.start(scheduler_address)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table style=\"border: 2px solid white;\">\n",
              "<tr>\n",
              "<td style=\"vertical-align: top; border: 0px solid white\">\n",
              "<h3>Client</h3>\n",
              "<ul>\n",
              "  <li><b>Scheduler: </b>inproc://172.28.0.2/5596/32\n",
              "</ul>\n",
              "</td>\n",
              "<td style=\"vertical-align: top; border: 0px solid white\">\n",
              "<h3>Cluster</h3>\n",
              "<ul>\n",
              "  <li><b>Workers: </b>1</li>\n",
              "  <li><b>Cores: </b>2</li>\n",
              "  <li><b>Memory: </b>13.66 GB</li>\n",
              "</ul>\n",
              "</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<Client: scheduler='inproc://172.28.0.2/5596/32' processes=1 cores=2>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2tMnwAEmqpF",
        "colab_type": "text"
      },
      "source": [
        "Set up the path  to data and output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-tLiFKrmZDM",
        "colab_type": "code",
        "outputId": "bb5783f4-21e8-43d2-b182-cf95b3cb74cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "path = '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_input'\n",
        "path_output = '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output'\n",
        "\n",
        "!ls \"/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_input\"\n",
        "!ls '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output/dask_edge_list'\n",
        "!ls '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output'"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "buildings_raw.cpg      buildings_raw_pts.mshp  buildings_raw.shp\n",
            "buildings_raw.dbf      buildings_raw_pts.prj   buildings_raw.shx\n",
            "buildings_raw.prj      buildings_raw_pts.shp   GD_wind.csv\n",
            "buildings_raw_pts.cpg  buildings_raw_pts.shx   source_target.csv\n",
            "buildings_raw_pts.dbf  buildings_raw.qpj\n",
            "edge_data.parquet\n",
            "dask_edge_list\t\t\t    output_scenario_0_step_45.parquet\n",
            "output_scenario_0_step_0.parquet    output_scenario_0_step_46.parquet\n",
            "output_scenario_0_step_100.parquet  output_scenario_0_step_47.parquet\n",
            "output_scenario_0_step_101.parquet  output_scenario_0_step_48.parquet\n",
            "output_scenario_0_step_102.parquet  output_scenario_0_step_49.parquet\n",
            "output_scenario_0_step_103.parquet  output_scenario_0_step_4.parquet\n",
            "output_scenario_0_step_104.parquet  output_scenario_0_step_50.parquet\n",
            "output_scenario_0_step_105.parquet  output_scenario_0_step_51.parquet\n",
            "output_scenario_0_step_106.parquet  output_scenario_0_step_52.parquet\n",
            "output_scenario_0_step_107.parquet  output_scenario_0_step_53.parquet\n",
            "output_scenario_0_step_108.parquet  output_scenario_0_step_54.parquet\n",
            "output_scenario_0_step_109.parquet  output_scenario_0_step_55.parquet\n",
            "output_scenario_0_step_10.parquet   output_scenario_0_step_56.parquet\n",
            "output_scenario_0_step_110.parquet  output_scenario_0_step_57.parquet\n",
            "output_scenario_0_step_111.parquet  output_scenario_0_step_58.parquet\n",
            "output_scenario_0_step_112.parquet  output_scenario_0_step_59.parquet\n",
            "output_scenario_0_step_113.parquet  output_scenario_0_step_5.parquet\n",
            "output_scenario_0_step_114.parquet  output_scenario_0_step_60.parquet\n",
            "output_scenario_0_step_115.parquet  output_scenario_0_step_61.parquet\n",
            "output_scenario_0_step_116.parquet  output_scenario_0_step_62.parquet\n",
            "output_scenario_0_step_117.parquet  output_scenario_0_step_63.parquet\n",
            "output_scenario_0_step_118.parquet  output_scenario_0_step_64.parquet\n",
            "output_scenario_0_step_119.parquet  output_scenario_0_step_65.parquet\n",
            "output_scenario_0_step_11.parquet   output_scenario_0_step_66.parquet\n",
            "output_scenario_0_step_120.parquet  output_scenario_0_step_67.parquet\n",
            "output_scenario_0_step_12.parquet   output_scenario_0_step_68.parquet\n",
            "output_scenario_0_step_13.parquet   output_scenario_0_step_69.parquet\n",
            "output_scenario_0_step_14.parquet   output_scenario_0_step_6.parquet\n",
            "output_scenario_0_step_15.parquet   output_scenario_0_step_70.parquet\n",
            "output_scenario_0_step_16.parquet   output_scenario_0_step_71.parquet\n",
            "output_scenario_0_step_17.parquet   output_scenario_0_step_72.parquet\n",
            "output_scenario_0_step_18.parquet   output_scenario_0_step_73.parquet\n",
            "output_scenario_0_step_19.parquet   output_scenario_0_step_74.parquet\n",
            "output_scenario_0_step_1.parquet    output_scenario_0_step_75.parquet\n",
            "output_scenario_0_step_20.parquet   output_scenario_0_step_76.parquet\n",
            "output_scenario_0_step_21.parquet   output_scenario_0_step_77.parquet\n",
            "output_scenario_0_step_22.parquet   output_scenario_0_step_78.parquet\n",
            "output_scenario_0_step_23.parquet   output_scenario_0_step_79.parquet\n",
            "output_scenario_0_step_24.parquet   output_scenario_0_step_7.parquet\n",
            "output_scenario_0_step_25.parquet   output_scenario_0_step_80.parquet\n",
            "output_scenario_0_step_26.parquet   output_scenario_0_step_81.parquet\n",
            "output_scenario_0_step_27.parquet   output_scenario_0_step_82.parquet\n",
            "output_scenario_0_step_28.parquet   output_scenario_0_step_83.parquet\n",
            "output_scenario_0_step_29.parquet   output_scenario_0_step_84.parquet\n",
            "output_scenario_0_step_2.parquet    output_scenario_0_step_85.parquet\n",
            "output_scenario_0_step_30.parquet   output_scenario_0_step_86.parquet\n",
            "output_scenario_0_step_31.parquet   output_scenario_0_step_87.parquet\n",
            "output_scenario_0_step_32.parquet   output_scenario_0_step_88.parquet\n",
            "output_scenario_0_step_33.parquet   output_scenario_0_step_89.parquet\n",
            "output_scenario_0_step_34.parquet   output_scenario_0_step_8.parquet\n",
            "output_scenario_0_step_35.parquet   output_scenario_0_step_90.parquet\n",
            "output_scenario_0_step_36.parquet   output_scenario_0_step_91.parquet\n",
            "output_scenario_0_step_37.parquet   output_scenario_0_step_92.parquet\n",
            "output_scenario_0_step_38.parquet   output_scenario_0_step_93.parquet\n",
            "output_scenario_0_step_39.parquet   output_scenario_0_step_94.parquet\n",
            "output_scenario_0_step_3.parquet    output_scenario_0_step_95.parquet\n",
            "output_scenario_0_step_40.parquet   output_scenario_0_step_96.parquet\n",
            "output_scenario_0_step_41.parquet   output_scenario_0_step_97.parquet\n",
            "output_scenario_0_step_42.parquet   output_scenario_0_step_98.parquet\n",
            "output_scenario_0_step_43.parquet   output_scenario_0_step_99.parquet\n",
            "output_scenario_0_step_44.parquet   output_scenario_0_step_9.parquet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6kl25fSmjGN",
        "colab_type": "text"
      },
      "source": [
        "**Functions**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2p6Jyt2zj0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_up_file(path, prefix):\n",
        "    files = glob.glob(os.path.join(path, prefix))\n",
        "    for file in files:\n",
        "        print(file)\n",
        "        os.remove(file)\n",
        "        # shutil.rmtree(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9H08CSY1fhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wind scenario\n",
        "def wind_scenario(file_name):\n",
        "    # wind scenario conditions\n",
        "    wind_data = pd.read_csv(os.path.join(path, file_name))\n",
        "    i = np.random.randint(0, wind_data.shape[0])\n",
        "    w = wind_data.iloc[i, 2]\n",
        "    d = wind_data.iloc[i, 1]\n",
        "    b = wind_data.iloc[i, 3]\n",
        "    # wind direction\n",
        "    wind_bearing_max = b + 45\n",
        "    wind_bearing_min = b - 45\n",
        "    if b == 360:\n",
        "        wind_bearing_max = 45\n",
        "    if b <= 0:  # should not be necessary\n",
        "        wind_bearing_min = 0\n",
        "    if b == 999:\n",
        "        wind_bearing_max = 999\n",
        "        wind_bearing_min = 0\n",
        "    \n",
        "    return wind_bearing_max, wind_bearing_min, d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIjsYRaVMvp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create ignitions\n",
        "def ignitions(edges, scenario):\n",
        "    # add random column\n",
        "    edges['rng'] = np.random.uniform(0, 1, size=len(edges))\n",
        "    # filter on random column\n",
        "    fires = edges[edges.rng < edges.IgnProb_bl]\n",
        "\n",
        "    fires['step'] = 0\n",
        "    fires['scenario'] = scenario\n",
        "\n",
        "    return fires"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMwRlajrMvoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# conditions of fire propagation\n",
        "def conditions_spread(fires,burn,wind_bearing_max,wind_bearing_min,wind_distance,\n",
        "                      scenario, step):\n",
        "    # add columns to ddf\n",
        "    fires['wind_bearing_max'] = wind_bearing_max\n",
        "    fires['wind_bearing_min'] = wind_bearing_min\n",
        "    fires['wind_distance'] = wind_distance\n",
        "    # wind speed -> neighbors selection from wind buffer\n",
        "    new_fires = fires[fires.distance < fires.wind_distance]\n",
        "    # wind direction\n",
        "    new_fires = new_fires[(new_fires.bearing < new_fires.wind_bearing_max) & (new_fires.bearing < new_fires.wind_bearing_min)]\n",
        "    # should not be already burnt\n",
        "    new_fires = new_fires[~new_fires.target.isin(burn)]\n",
        "\n",
        "    # add columns\n",
        "    new_fires['step'] = step\n",
        "    new_fires['scenario'] = scenario\n",
        "\n",
        "    # log burnt assets\n",
        "    burn.extend(fires.source)\n",
        "    # remove duplicates from burn list\n",
        "    burn = list(set(burn))\n",
        "\n",
        "    # export active fire to parquet for record\n",
        "    fires.to_parquet(os.path.join(path_output, \n",
        "                                   'output_scenario_{}_step_{}.parquet'.format(scenario, step)), engine='pyarrow')\n",
        "    \n",
        "    return new_fires, burn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM3CVlxYMvmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spreading fire\n",
        "def new_fires(fires, edges):\n",
        "  fires_list = list(set(fires.target))\n",
        "  new_fires = edges[edges.source.isin(fires_list)]\n",
        "  return new_fires"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x38ekV6Tfp4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# log burned assets\n",
        "def record_burnt_assets_for_scenario(step, scenario):\n",
        "  files = glob.glob(os.path.join(path_output, \"*scenario_{}*\".format(scenario)))\n",
        "  for i, file in enumerate(files):\n",
        "    burn_ddf = dd.from_pandas(file, npartitions=cpu_count())\n",
        "    #export to parquet\n",
        "    burn_df.to_parquet(os.path.join(path_output, \n",
        "                                  'output_scenario_{}.parquet'.format(scenario)), engine='pyarrow')\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulo9yu2MaP-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display network\n",
        "def display_network(edge_list_dataframe):\n",
        "    graph = nx.from_pandas_edgelist(edge_list_dataframe, edge_attr=True)\n",
        "    options = {'node_color': 'red', 'node_size': 50, 'width': 1, 'alpha': 0.4,\n",
        "               'with_labels': False, 'font_weight': 'bold'}\n",
        "    nx.draw_kamada_kawai(graph, **options)\n",
        "    plt.show()\n",
        "    return graph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa9nJc2nMvi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run main\n",
        "def main(number_of_scenarios, edges):\n",
        "  # --- SCENARIOS\n",
        "  print(\"number of scenarios : {}\".format(number_of_scenarios))\n",
        "  for scenario in range(number_of_scenarios):\n",
        "      list_BURNED = []\n",
        "      BURNED = [] # pd.DataFrame(columns=['source','target','distance', 'bearing',\n",
        "                                      # 'IgnProb_bl', 'scenario', 'step'])\n",
        "      print(\"--- SCENARIO : {}\".format(scenario))\n",
        "      FIRES = ignitions(EDGES, scenario)\n",
        "      if len(FIRES) == 0:\n",
        "          print(\"no fire\")\n",
        "          continue\n",
        "      wind_bearing_max, wind_bearing_min, wind_distance = wind_scenario('GD_wind.csv') # no filtering, just adding wind info to dataframe\n",
        "      # --------- STEPS\n",
        "      for step in range(len(EDGES)):\n",
        "          # print(\"--------- STEP : {}\".format(step))\n",
        "          FIRES, BURNED = conditions_spread(FIRES, BURNED, wind_bearing_max, wind_bearing_min, wind_distance,scenario, step) # filtering\n",
        "          # list_BURNED.append(BURNED)\n",
        "          if len(FIRES) == 0:\n",
        "            print(\"no more fire\")\n",
        "            break\n",
        "          FIRES = new_fires(FIRES, edges)\n",
        "\n",
        "      # record burnt assets per scenario COULD BE DONE IN POSTPROCESSING\n",
        "      # record_burnt_assets_for_scenario(BURNED, scenario)\n",
        "\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcnbVvdTH22W",
        "colab_type": "text"
      },
      "source": [
        "**Clean up directories and load data**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZwNZ3Vrzzc9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "77311605-603e-4559-a30f-d1645d87888c"
      },
      "source": [
        "clean_up_file(path_output, \"output*\")"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output/output_scenario_0_step_0.parquet\n",
            "/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output/output_scenario_0_step_1.parquet\n",
            "/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output/output_scenario_0_step_2.parquet\n",
            "/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output/output_scenario_0_step_3.parquet\n",
            "/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output/output_scenario_0_step_4.parquet\n",
            "/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output/output_scenario_0_step_5.parquet\n",
            "/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output/output_scenario_0_step_6.parquet\n",
            "/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output/output_scenario_0_step_7.parquet\n",
            "/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output/output_scenario_0_step_8.parquet\n",
            "/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output/output_scenario_0_step_9.parquet\n",
            "/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output/output_scenario_0_step_10.parquet\n",
            "/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output/output_scenario_0_step_11.parquet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0oZS_vBsODJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "deab9852-4760-4271-f555-a151fe72cecf"
      },
      "source": [
        "!ls '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output'"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dask_edge_list\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXDI561DMvg0",
        "colab_type": "code",
        "outputId": "7030f938-7d84-4656-c5f0-d0fc89135a81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%%time\n",
        "%memit\n",
        "# load data\n",
        "# EDGES = dd.read_parquet(os.path.join(path_output, 'dask_edge_list', 'edge_data.parquet'), engine='pyarrow')\n",
        "EDGES = pd.read_parquet(os.path.join(path_output, 'dask_edge_list', 'edge_data.parquet'), engine='pyarrow')\n",
        "print(\"number of edges : {}\".format(len(EDGES)))\n",
        "# G = display_network(EDGES)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "peak memory: 1331.66 MiB, increment: 0.00 MiB\n",
            "number of edges : 3457222\n",
            "CPU times: user 767 ms, sys: 430 ms, total: 1.2 s\n",
            "Wall time: 1.18 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-_LNjHFIBga",
        "colab_type": "text"
      },
      "source": [
        "**Run the algorithm**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_1D-wW9Mvfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "%memit\n",
        "# run main\n",
        "main(1001, EDGES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5qhwhR9ILWd",
        "colab_type": "text"
      },
      "source": [
        "**Manage output and postprocessing**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NxYaqTTnhVxD",
        "colab": {}
      },
      "source": [
        "remove parquet_file\n",
        "clean_up_file(path_output, \"output*\")\n",
        "!ls '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F13amArPPQPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%time\n",
        "# %memit\n",
        "# df.to_parquet(os.path.join(path_output,'final.parquet'), engine='pyarrow')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41it5akWV4OY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files = glob.glob(os.path.join(path_output, \"output*\"))\n",
        "df = dd.read_parquet(files)\n",
        "df = pd.concat((pd.read_csv(f) for f in all_files))\n",
        "# get the count of unique burn id per scenario\n",
        "df.groupby('scenario').source.nunique().compute()\n",
        "# count id \n",
        "df.groupby('source')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}