{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/37stu37/FFE/blob/master/FFE_network_one_file_run.ipynb",
      "authorship_tag": "ABX9TyP2fpL9OBzDISoggvZ/rSly",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/37stu37/FFE/blob/master/FFE_numba_Dask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGCGL2eCzyEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time \n",
        "%%capture\n",
        "!apt update\n",
        "!apt upgrade\n",
        "!apt install gdal-bin python-gdal python3-gdal \n",
        "# Install rtree - Geopandas requirment\n",
        "!apt install python3-rtree \n",
        "# Install Geopandas\n",
        "!pip install git+git://github.com/geopandas/geopandas.git\n",
        "# Install descartes - Geopandas requirment\n",
        "!pip install descartes \n",
        "!pip install memory_profiler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PipQ4HNTjKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "%tensorflow_version 2.x\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr0PZxCvmWCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "import datetime\n",
        "import glob\n",
        "import shutil\n",
        "from math import sqrt\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import bokeh\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from scipy.spatial import distance\n",
        "from shapely.geometry import box\n",
        "from shapely.geometry import shape\n",
        "from shapely.geometry import Point\n",
        "import networkx as nx\n",
        "from sys import getsizeof\n",
        "from numba import jit\n",
        "import dask.dataframe as dd\n",
        "import dask.array as da\n",
        "import dask\n",
        "from dask.distributed import Client\n",
        "from dask.diagnostics import ProgressBar\n",
        "%matplotlib inline\n",
        "%load_ext memory_profiler\n",
        "\n",
        "pd.options.mode.chained_assignment = None  # default='warn'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz4lyV9f3Sny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "client = Client(processes=False)\n",
        "client"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2tMnwAEmqpF",
        "colab_type": "text"
      },
      "source": [
        "Set up the path  to data and output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-tLiFKrmZDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_input'\n",
        "path_output = '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output'\n",
        "\n",
        "!ls \"/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_input\"\n",
        "!ls '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output/dask_edge_list'\n",
        "!ls '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6kl25fSmjGN",
        "colab_type": "text"
      },
      "source": [
        "**Functions**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2p6Jyt2zj0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_up_file(path, prefix):\n",
        "    files = glob.glob(os.path.join(path, prefix))\n",
        "    for file in files:\n",
        "        print(file)\n",
        "        os.remove(file)\n",
        "        # shutil.rmtree(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9H08CSY1fhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wind scenario\n",
        "def wind_scenario(file_name):\n",
        "    # wind scenario conditions\n",
        "    wind_data = pd.read_csv(os.path.join(path, file_name))\n",
        "    i = np.random.randint(0, wind_data.shape[0])\n",
        "    w = wind_data.iloc[i, 2]\n",
        "    d = wind_data.iloc[i, 1]\n",
        "    b = wind_data.iloc[i, 3]\n",
        "    # wind direction\n",
        "    wind_bearing_max = b + 45\n",
        "    wind_bearing_min = b - 45\n",
        "    if b == 360:\n",
        "        wind_bearing_max = 45\n",
        "    if b <= 0:  # should not be necessary\n",
        "        wind_bearing_min = 0\n",
        "    if b == 999:\n",
        "        wind_bearing_max = 999\n",
        "        wind_bearing_min = 0\n",
        "    \n",
        "    return wind_bearing_max, wind_bearing_min, d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIjsYRaVMvp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create ignitions\n",
        "def ignitions(edges, scenario):\n",
        "    # add random column\n",
        "    edges['rng'] = np.random.uniform(0, 1, size=len(edges))\n",
        "    # filter on random column\n",
        "    fires = edges[edges.rng < edges.IgnProb_bl]\n",
        "\n",
        "    fires['step'] = 0\n",
        "    fires['scenario'] = scenario\n",
        "\n",
        "    return fires"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMwRlajrMvoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# conditions of fire propagation\n",
        "def conditions_spread(fires,burn,wind_bearing_max,wind_bearing_min,wind_distance,\n",
        "                      scenario, step):\n",
        "    # add columns to ddf\n",
        "    fires['wind_bearing_max'] = wind_bearing_max\n",
        "    fires['wind_bearing_min'] = wind_bearing_min\n",
        "    fires['wind_distance'] = wind_distance\n",
        "    # wind speed -> neighbors selection from wind buffer\n",
        "    new_fires = fires[fires.distance < fires.wind_distance]\n",
        "    # wind direction\n",
        "    new_fires = new_fires[(new_fires.bearing < new_fires.wind_bearing_max) & (new_fires.bearing < new_fires.wind_bearing_min)]\n",
        "    # should not be already burnt\n",
        "    new_fires = new_fires[~new_fires.target.isin(burn)]\n",
        "\n",
        "    # add columns\n",
        "    new_fires['step'] = step\n",
        "    new_fires['scenario'] = scenario\n",
        "\n",
        "    # log burnt assets\n",
        "    burn.extend(fires.source)\n",
        "    # remove duplicates from burn list\n",
        "    burn = list(set(burn))\n",
        "\n",
        "    # export active fire to parquet for record\n",
        "    fires.to_parquet(os.path.join(path_output, \n",
        "                                   'output_scenario_{}_step_{}.parquet'.format(scenario, step)), engine='pyarrow')\n",
        "    \n",
        "    return new_fires, burn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM3CVlxYMvmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spreading fire\n",
        "def new_fires(fires, edges):\n",
        "  fires_list = list(set(fires.target))\n",
        "  new_fires = edges[edges.source.isin(fires_list)]\n",
        "  return new_fires"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x38ekV6Tfp4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# log burned assets\n",
        "@dask.delayed\n",
        "def record_burnt_assets_for_scenario(scenario):\n",
        "  L = []\n",
        "  files = glob.glob(os.path.join(path_output, \"*output_scenario_{}*\".format(scenario)))\n",
        "  for file in files:\n",
        "    pqt = dd.read_parquet(file)\n",
        "    L.append(pqt)\n",
        "    os.remove(pqt)\n",
        "  df = dd.concat(L)\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDoaZtl4IP2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_fid_occurences(df, scenario):\n",
        "  count = df.source.value_counts().compute()\n",
        "  count_df = count.to_frame()\n",
        "  count_df['count'] = count\n",
        "  count_df['source'] = count_df.index\n",
        "  count_df['scenario'] = scenario\n",
        "  count_df = count_df.reset_index()\n",
        "  count_df = count_df.drop(columns='index')\n",
        "  count_df.to_parquet(os.path.join(path_output, \n",
        "                                   'output_scenario_{}.parquet'.format(scenario)), engine='pyarrow')\n",
        "  return print('output_scenario_{}.parquet created'.format(scenario))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulo9yu2MaP-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display network\n",
        "def display_network(edge_list_dataframe):\n",
        "    graph = nx.from_pandas_edgelist(edge_list_dataframe, edge_attr=True)\n",
        "    options = {'node_color': 'red', 'node_size': 50, 'width': 1, 'alpha': 0.4,\n",
        "               'with_labels': False, 'font_weight': 'bold'}\n",
        "    nx.draw_kamada_kawai(graph, **options)\n",
        "    plt.show()\n",
        "    return graph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa9nJc2nMvi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run main\n",
        "def main(number_of_scenarios, edges):\n",
        "  # --- SCENARIOS\n",
        "  print(\"number of scenarios : {}\".format(number_of_scenarios))\n",
        "  for scenario in range(number_of_scenarios):\n",
        "      list_BURNED = []\n",
        "      BURNED = [] # pd.DataFrame(columns=['source','target','distance', 'bearing',\n",
        "                                      # 'IgnProb_bl', 'scenario', 'step'])\n",
        "      print(\"--- SCENARIO : {}\".format(scenario))\n",
        "      FIRES = ignitions(EDGES, scenario)\n",
        "      if len(FIRES) == 0:\n",
        "          print(\"no fire\")\n",
        "          continue\n",
        "      wind_bearing_max, wind_bearing_min, wind_distance = wind_scenario('GD_wind.csv') # no filtering, just adding wind info to dataframe\n",
        "      # --------- STEPS\n",
        "      for step in range(len(EDGES)):\n",
        "          # print(\"--------- STEP : {}\".format(step))\n",
        "          FIRES, BURNED = conditions_spread(FIRES, BURNED, wind_bearing_max, wind_bearing_min, wind_distance,scenario, step) # filtering\n",
        "          # list_BURNED.append(BURNED)\n",
        "          if len(FIRES) == 0:\n",
        "            print(\"no more fire\")\n",
        "            break\n",
        "          FIRES = new_fires(FIRES, edges)\n",
        "\n",
        "      record = record_burnt_assets_for_scenario(scenario)\n",
        "      count_fid_occurences(record, scenario)\n",
        "\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcnbVvdTH22W",
        "colab_type": "text"
      },
      "source": [
        "**Clean up directories and load data**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZwNZ3Vrzzc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_up_file(path_output, \"output*\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0oZS_vBsODJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXDI561DMvg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "%memit\n",
        "# load data\n",
        "# EDGES = dd.read_parquet(os.path.join(path_output, 'dask_edge_list', 'edge_data.parquet'), engine='pyarrow')\n",
        "EDGES = pd.read_parquet(os.path.join(path_output, 'dask_edge_list', 'edge_data.parquet'), engine='pyarrow')\n",
        "print(\"number of edges : {}\".format(len(EDGES)))\n",
        "# G = display_network(EDGES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-_LNjHFIBga",
        "colab_type": "text"
      },
      "source": [
        "**Run the algorithm**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_1D-wW9Mvfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "%memit\n",
        "# run main\n",
        "main(101, EDGES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5qhwhR9ILWd",
        "colab_type": "text"
      },
      "source": [
        "**Manage output and postprocessing**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NxYaqTTnhVxD",
        "colab": {}
      },
      "source": [
        "# remove parquet_file\n",
        "clean_up_file(path_output, \"output*\")\n",
        "!ls '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F13amArPPQPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%time\n",
        "# %memit\n",
        "# df.to_parquet(os.path.join(path_output,'final.parquet'), engine='pyarrow')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41it5akWV4OY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files = glob.glob(os.path.join(path_output, \"output*\"))\n",
        "df = dd.read_parquet(files)\n",
        "df = pd.concat((pd.read_csv(f) for f in all_files))\n",
        "# get the count of unique burn id per scenario\n",
        "df.groupby('scenario').source.nunique().compute()\n",
        "# count id \n",
        "df.groupby('source')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}