{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/37stu37/FFE/blob/master/FFE_network_one_file_run.ipynb",
      "authorship_tag": "ABX9TyOH2NeLvjQ6XohFU/YAU1iu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/37stu37/FFE/blob/master/FFE_numba_Dask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGCGL2eCzyEv",
        "colab_type": "code",
        "outputId": "3f411d7d-9406-4d8a-aab3-23789104ae46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time \n",
        "%%capture\n",
        "!apt update\n",
        "!apt upgrade\n",
        "!apt install gdal-bin python-gdal python3-gdal \n",
        "# Install rtree - Geopandas requirment\n",
        "!apt install python3-rtree \n",
        "# Install Geopandas\n",
        "!pip install git+git://github.com/geopandas/geopandas.git\n",
        "# Install descartes - Geopandas requirment\n",
        "!pip install descartes \n",
        "!pip install memory_profiler"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 171 ms, sys: 52.1 ms, total: 223 ms\n",
            "Wall time: 25.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PipQ4HNTjKW",
        "colab_type": "code",
        "outputId": "464a8ded-8add-456c-d5c9-419d5bc2e965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "%tensorflow_version 2.x\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr0PZxCvmWCl",
        "colab_type": "code",
        "outputId": "53157ed4-1b8e-40a3-a517-8108988a79ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "import datetime\n",
        "import glob\n",
        "import shutil\n",
        "from math import sqrt\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import bokeh\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from scipy.spatial import distance\n",
        "from shapely.geometry import box\n",
        "from shapely.geometry import shape\n",
        "from shapely.geometry import Point\n",
        "import networkx as nx\n",
        "from sys import getsizeof\n",
        "from numba import jit\n",
        "import dask.dataframe as dd\n",
        "import dask.array as da\n",
        "import dask\n",
        "from dask.distributed import Client\n",
        "from dask.diagnostics import ProgressBar\n",
        "%matplotlib inline\n",
        "%load_ext memory_profiler\n",
        "\n",
        "pd.options.mode.chained_assignment = None  # default='warn'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 898 ms, sys: 85 ms, total: 983 ms\n",
            "Wall time: 1.13 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz4lyV9f3Sny",
        "colab_type": "code",
        "outputId": "9aecbb47-ab6a-4a84-bc4a-3f7a7303a100",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "source": [
        "client = Client(processes=False)\n",
        "client"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/distributed/bokeh/core.py:57: UserWarning: \n",
            "Failed to start diagnostics server on port 8787. [Errno 99] Cannot assign requested address\n",
            "  warnings.warn('\\n' + msg)\n",
            "/usr/local/lib/python3.6/dist-packages/distributed/deploy/local.py:197: UserWarning: \n",
            "Could not launch service 'bokeh' on port 8787. Got the following message:\n",
            "\n",
            "[Errno 99] Cannot assign requested address\n",
            "  self.scheduler.start(scheduler_address)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table style=\"border: 2px solid white;\">\n",
              "<tr>\n",
              "<td style=\"vertical-align: top; border: 0px solid white\">\n",
              "<h3>Client</h3>\n",
              "<ul>\n",
              "  <li><b>Scheduler: </b>inproc://172.28.0.2/7864/1\n",
              "</ul>\n",
              "</td>\n",
              "<td style=\"vertical-align: top; border: 0px solid white\">\n",
              "<h3>Cluster</h3>\n",
              "<ul>\n",
              "  <li><b>Workers: </b>1</li>\n",
              "  <li><b>Cores: </b>4</li>\n",
              "  <li><b>Memory: </b>27.40 GB</li>\n",
              "</ul>\n",
              "</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<Client: scheduler='inproc://172.28.0.2/7864/1' processes=1 cores=4>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2tMnwAEmqpF",
        "colab_type": "text"
      },
      "source": [
        "Set up the path  to data and output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-tLiFKrmZDM",
        "colab_type": "code",
        "outputId": "09177c1c-58b0-4fd9-be45-f14e30c5cdf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "path = '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_input'\n",
        "path_output = '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output'\n",
        "\n",
        "!ls \"/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_input\"\n",
        "!ls '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output/dask_edge_list'\n",
        "!ls '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "buildings_raw.cpg      buildings_raw_pts.mshp  buildings_raw.shp\n",
            "buildings_raw.dbf      buildings_raw_pts.prj   buildings_raw.shx\n",
            "buildings_raw.prj      buildings_raw_pts.shp   GD_wind.csv\n",
            "buildings_raw_pts.cpg  buildings_raw_pts.shx   source_target.csv\n",
            "buildings_raw_pts.dbf  buildings_raw.qpj\n",
            "edge_data.parquet\n",
            "dask_edge_list\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2p6Jyt2zj0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_up_file(path, prefix):\n",
        "    files = glob.glob(os.path.join(path, prefix))\n",
        "    for file in files:\n",
        "        print(file)\n",
        "        os.remove(file)\n",
        "        # shutil.rmtree(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6kl25fSmjGN",
        "colab_type": "text"
      },
      "source": [
        "Create the functions to be used by the algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9H08CSY1fhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wind scenario\n",
        "def wind_scenario(file_name):\n",
        "    # wind scenario conditions\n",
        "    wind_data = pd.read_csv(os.path.join(path, file_name))\n",
        "    i = np.random.randint(0, wind_data.shape[0])\n",
        "    w = wind_data.iloc[i, 2]\n",
        "    d = wind_data.iloc[i, 1]\n",
        "    b = wind_data.iloc[i, 3]\n",
        "    # wind direction\n",
        "    wind_bearing_max = b + 45\n",
        "    wind_bearing_min = b - 45\n",
        "    if b == 360:\n",
        "        wind_bearing_max = 45\n",
        "    if b <= 0:  # should not be necessary\n",
        "        wind_bearing_min = 0\n",
        "    if b == 999:\n",
        "        wind_bearing_max = 999\n",
        "        wind_bearing_min = 0\n",
        "    \n",
        "    return wind_bearing_max, wind_bearing_min, d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIjsYRaVMvp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create ignitions\n",
        "def ignitions(edges, scenario):\n",
        "    # add random column\n",
        "    edges['rng'] = np.random.uniform(0, 1, size=len(edges))\n",
        "    # filter on random column\n",
        "    fires = edges[edges.rng < edges.IgnProb_bl]\n",
        "\n",
        "    fires['step'] = 0\n",
        "    fires['scenario'] = scenario\n",
        "\n",
        "    return fires"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMwRlajrMvoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# conditions of fire propagation\n",
        "def conditions_spread(fires,burn,wind_bearing_max,wind_bearing_min,wind_distance,\n",
        "                      scenario, step):\n",
        "    # add columns to ddf\n",
        "    fires['wind_bearing_max'] = wind_bearing_max\n",
        "    fires['wind_bearing_min'] = wind_bearing_min\n",
        "    fires['wind_distance'] = wind_distance\n",
        "    # wind speed -> neighbors selection from wind buffer\n",
        "    new_fires = fires[fires.distance < fires.wind_distance]\n",
        "    # wind direction\n",
        "    new_fires = new_fires[(new_fires.bearing < new_fires.wind_bearing_max) & (new_fires.bearing < new_fires.wind_bearing_min)]\n",
        "    # should not be already burnt\n",
        "    burn_list = list(set(burn.source))\n",
        "    new_fires = new_fires[~new_fires.target.isin(burn_list)]\n",
        "    # burn_list.append(fires.source)\n",
        "\n",
        "    new_fires['step'] = step\n",
        "    new_fires['scenario'] = scenario\n",
        "\n",
        "    # log burnt assets\n",
        "    data = [burn, fires]\n",
        "    BURNED = pd.concat(data, axis=0)\n",
        "    return new_fires, BURNED"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM3CVlxYMvmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spreading fire\n",
        "def new_fires(fires, edges):\n",
        "  fires_list = list(set(fires.target))\n",
        "  new_fires = edges[edges.source.isin(fires_list)]\n",
        "  return new_fires"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x38ekV6Tfp4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# log burned assets\n",
        "def record_burnt_assets(list_of_burnt_assets, scenario):\n",
        "  burn_df = pd.concat(list_of_burnt_assets, sort=True)\n",
        "  # burn_ddf = dd.from_pandas(burn_df, npartitions=4)\n",
        "  #export to parquet\n",
        "  burn_df.to_parquet(os.path.join(path_output, \n",
        "                                   'output_scenario_{}.parquet'.format(scenario)), engine='pyarrow')\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFXc22be-OWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@dask.delayed\n",
        "def concatenate_outputs(prefix):\n",
        "  files = glob.glob(os.path.join(path_output, prefix))\n",
        "  for i, file in enumerate(files):\n",
        "      df = dd.read_parquet(files)\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulo9yu2MaP-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display network\n",
        "def display_network(edge_list_dataframe):\n",
        "    graph = nx.from_pandas_edgelist(edge_list_dataframe, edge_attr=True)\n",
        "    options = {'node_color': 'red', 'node_size': 50, 'width': 1, 'alpha': 0.4,\n",
        "               'with_labels': False, 'font_weight': 'bold'}\n",
        "    nx.draw_kamada_kawai(graph, **options)\n",
        "    plt.show()\n",
        "    return graph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZwNZ3Vrzzc9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09604f1a-bcf3-4a0d-c5af-07949f9c6185"
      },
      "source": [
        "clean_up_file(path_output, \"output*\")\n",
        "!ls '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output'"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dask_edge_list\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXDI561DMvg0",
        "colab_type": "code",
        "outputId": "c2582afc-2f06-4467-ad7d-e9c1c24a7523",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%%time\n",
        "%memit\n",
        "# load data\n",
        "# EDGES = dd.read_parquet(os.path.join(path_output, 'dask_edge_list', 'edge_data.parquet'), engine='pyarrow')\n",
        "EDGES = pd.read_parquet(os.path.join(path_output, 'dask_edge_list', 'edge_data.parquet'), engine='pyarrow')\n",
        "print(\"number of edges : {}\".format(len(EDGES)))\n",
        "\n",
        "# G = display_network(EDGES)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "peak memory: 287.28 MiB, increment: 0.02 MiB\n",
            "number of edges : 3457222\n",
            "CPU times: user 343 ms, sys: 260 ms, total: 603 ms\n",
            "Wall time: 509 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NSp4UAgOKZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9501379-8fd0-4570-e8ce-1f71dac72012"
      },
      "source": [
        "len(EDGES)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3457222"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa9nJc2nMvi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run main\n",
        "def main(number_of_scenarios, edges):\n",
        "  # --- SCENARIOS\n",
        "  print(\"number of scenarios : {}\".format(number_of_scenarios))\n",
        "  for scenario in range(number_of_scenarios):\n",
        "      list_BURNED = []\n",
        "      BURNED = pd.DataFrame(columns=['source','target','distance', 'bearing',\n",
        "                                      'IgnProb_bl', 'scenario', 'step'])\n",
        "      print(\"--- SCENARIO : {}\".format(scenario))\n",
        "      FIRES = ignitions(EDGES, scenario)\n",
        "      if len(FIRES) == 0:\n",
        "          print(\"no fire\")\n",
        "          continue\n",
        "      wind_bearing_max, wind_bearing_min, wind_distance = wind_scenario('GD_wind.csv') # no filtering, just adding wind info to dataframe\n",
        "      # --------- STEPS\n",
        "      for step in range(len(EDGES)):\n",
        "          print(\"--------- STEP : {}\".format(step))\n",
        "          FIRES, BURNED = conditions_spread(FIRES, BURNED, wind_bearing_max, wind_bearing_min, wind_distance,scenario, step) # filtering\n",
        "          list_BURNED.append(BURNED)\n",
        "          if len(FIRES) == 0:\n",
        "            print(\"no more fire\")\n",
        "            break\n",
        "          FIRES = new_fires(FIRES, edges)\n",
        "\n",
        "      # record scenario burnt assets\n",
        "      record_burnt_assets(list_BURNED, scenario)\n",
        "\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_1D-wW9Mvfd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6bd576d6-20d1-4f74-8ebc-459d36a8726e"
      },
      "source": [
        "%%time\n",
        "%memit\n",
        "# run main\n",
        "main(5, EDGES)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "peak memory: 459.64 MiB, increment: 0.17 MiB\n",
            "number of scenarios : 5\n",
            "--- SCENARIO : 0\n",
            "--------- STEP : 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
            "of pandas will change to not sort by default.\n",
            "\n",
            "To accept the future behavior, pass 'sort=False'.\n",
            "\n",
            "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------- STEP : 1\n",
            "--------- STEP : 2\n",
            "--------- STEP : 3\n",
            "--------- STEP : 4\n",
            "--------- STEP : 5\n",
            "no more fire\n",
            "--- SCENARIO : 1\n",
            "--------- STEP : 0\n",
            "no more fire\n",
            "--- SCENARIO : 2\n",
            "--------- STEP : 0\n",
            "--------- STEP : 1\n",
            "--------- STEP : 2\n",
            "--------- STEP : 3\n",
            "--------- STEP : 4\n",
            "--------- STEP : 5\n",
            "--------- STEP : 6\n",
            "--------- STEP : 7\n",
            "--------- STEP : 8\n",
            "--------- STEP : 9\n",
            "--------- STEP : 10\n",
            "--------- STEP : 11\n",
            "--------- STEP : 12\n",
            "--------- STEP : 13\n",
            "--------- STEP : 14\n",
            "--------- STEP : 15\n",
            "--------- STEP : 16\n",
            "--------- STEP : 17\n",
            "--------- STEP : 18\n",
            "--------- STEP : 19\n",
            "--------- STEP : 20\n",
            "--------- STEP : 21\n",
            "--------- STEP : 22\n",
            "--------- STEP : 23\n",
            "--------- STEP : 24\n",
            "--------- STEP : 25\n",
            "--------- STEP : 26\n",
            "--------- STEP : 27\n",
            "--------- STEP : 28\n",
            "--------- STEP : 29\n",
            "--------- STEP : 30\n",
            "--------- STEP : 31\n",
            "--------- STEP : 32\n",
            "--------- STEP : 33\n",
            "--------- STEP : 34\n",
            "--------- STEP : 35\n",
            "--------- STEP : 36\n",
            "--------- STEP : 37\n",
            "--------- STEP : 38\n",
            "--------- STEP : 39\n",
            "--------- STEP : 40\n",
            "--------- STEP : 41\n",
            "--------- STEP : 42\n",
            "--------- STEP : 43\n",
            "--------- STEP : 44\n",
            "--------- STEP : 45\n",
            "--------- STEP : 46\n",
            "--------- STEP : 47\n",
            "--------- STEP : 48\n",
            "no more fire\n",
            "--- SCENARIO : 3\n",
            "--------- STEP : 0\n",
            "--------- STEP : 1\n",
            "--------- STEP : 2\n",
            "--------- STEP : 3\n",
            "--------- STEP : 4\n",
            "--------- STEP : 5\n",
            "--------- STEP : 6\n",
            "--------- STEP : 7\n",
            "--------- STEP : 8\n",
            "--------- STEP : 9\n",
            "--------- STEP : 10\n",
            "--------- STEP : 11\n",
            "--------- STEP : 12\n",
            "--------- STEP : 13\n",
            "--------- STEP : 14\n",
            "--------- STEP : 15\n",
            "--------- STEP : 16\n",
            "--------- STEP : 17\n",
            "--------- STEP : 18\n",
            "--------- STEP : 19\n",
            "--------- STEP : 20\n",
            "--------- STEP : 21\n",
            "--------- STEP : 22\n",
            "--------- STEP : 23\n",
            "--------- STEP : 24\n",
            "--------- STEP : 25\n",
            "--------- STEP : 26\n",
            "--------- STEP : 27\n",
            "--------- STEP : 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OBq7nnvBohn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "%memit\n",
        "df = concatenate_outputs(path_output, \"scenario*\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q7xFjSo-LCSC",
        "colab": {}
      },
      "source": [
        "remove parquet_file\n",
        "clean_up_file(path_output, \"output*\")\n",
        "!ls '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F13amArPPQPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "%memit\n",
        "df.to_parquet(os.path.join(path_output,'final.parquet'), engine='pyarrow')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMY_nW6oXo-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%time\n",
        "# # check convergence\n",
        "# from itertools import groupby\n",
        "# number_of_burns_per_scenarios = [len(list(group)) for key, group in groupby(scos)]\n",
        "# cumulative_number_of_burns_per_scenarios = list(np.cumsum(number_of_burns_per_scenarios))\n",
        "# scenario_list = list(set(scos))\n",
        "# scenario_list = [x+1 for x in scenario_list]\n",
        "\n",
        "# average_burn_per_scenario = [c / s for c,s in zip(cumulative_number_of_burns_per_scenarios, scenario_list)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW0ImekxY5FA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.plot(scenario_list, average_burn_per_scenario)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}