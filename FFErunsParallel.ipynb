{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "FFErunsParallel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/37stu37/FFE/blob/master/FFErunsParallel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q60FM7ZmLRAp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4cd41312-cf4b-42d2-9af0-2acd176a3d09"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVopy6D8J8u5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "991f8e63-91fa-4473-dc83-8502b671c18d"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m42Qt2fkaDi8",
        "colab_type": "text"
      },
      "source": [
        "**Imports**\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKZJJqJ6DNv-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1d49f9f1-0ba9-487f-d413-e8753b0032a5"
      },
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/01_Repository/FFE"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/01_Repository/FFE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XlNrKZfdLpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install memory_profiler\n",
        "!pip install git+https://github.com/dask/fastparquet"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O35x2t8T4Dk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import memory_profiler as mem_profile\n",
        "import sys\n",
        "import os\n",
        "import glob\n",
        "import multiprocessing as mp\n",
        "# import zipfile\n",
        "from zipfile import ZipFile \n",
        "\n",
        "\n",
        "pd.options.mode.chained_assignment = None  # default='warn'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k0T2KtSZ6iK",
        "colab_type": "text"
      },
      "source": [
        "**Load data from zip file**\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRP6grinJyed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "edge_file = './output/FinnShapeEdges.parquet'\n",
        "wind_file = './data/Copy of GD_wind.csv'\n",
        "folder = '../../02_Output/ffeFinnComparison'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtfIG4oqTqPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data\n",
        "wind_data = pd.read_csv(wind_file) \n",
        "edgelist = pd.read_parquet(edge_file, engine='pyarrow')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7pHNrjZN8Zw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "a2c6fedf-1032-41fb-895f-09aaefedc2b5"
      },
      "source": [
        "**Definitions**\n",
        "---\n",
        "\n",
        "\n",
        "# %%timeit\n",
        "def wind_scenario(wind_data):\n",
        "      i = np.random.randint(0, wind_data.values.shape[0])\n",
        "      w = wind_data.values[i, 2]\n",
        "      dist = wind_data.values[i, 1]\n",
        "      b = wind_data.values[i, 3]\n",
        "      bear_max = b + 45  # wind direction\n",
        "      bear_min = b - 45\n",
        "      if b == 360:\n",
        "          bear_max = 45\n",
        "      if b <= 0:  # should not be necessary\n",
        "          bear_min = 0\n",
        "      if b == 999:\n",
        "          bear_max = 999\n",
        "          bear_min = 0\n",
        "      return bear_max, bear_min, dist # wind characteristics, bearing and distance\n",
        "\n",
        "\n",
        "def ignition(edges=edgelist):\n",
        "    rng = np.random.uniform(0, 1, size=edges.values.shape[0])\n",
        "    mask = rng < edges.IgnProbBld.values\n",
        "    NewActiveEdges = edges[mask]\n",
        "    return NewActiveEdges\n",
        "\n",
        "\n",
        "def mask(t, activeEdges_d, listActivatedSources_d, w_b_max, w_b_min, w_d):\n",
        "    if t==0: # special case at time=0\n",
        "        return activeEdges_d\n",
        "    else:\n",
        "        mask = (activeEdges_d.bearing.values < w_b_max) & (activeEdges_d.bearing.values < w_b_min) & (activeEdges_d.distance < w_d)\n",
        "        NewActiveEdges = activeEdges_d[mask]\n",
        "        NewActiveEdges = NewActiveEdges[~NewActiveEdges.source.isin(listActivatedSources_d)]\n",
        "        return NewActiveEdges\n",
        "\n",
        "\n",
        "def propagation(activeEdges_d, edges=edgelist):\n",
        "    NewActiveEdges = edges[edges.source.isin(activeEdges_d.target)]\n",
        "    return NewActiveEdges\n",
        "\n",
        "\n",
        "def clean_up(path):\n",
        "    files = glob.glob(path)\n",
        "    print(\" {} files removed\".format(len(files)))\n",
        "    for f in files:\n",
        "      os.remove(f)\n",
        "\n",
        "\n",
        "def ffe_runs(n):\n",
        "    for scenario in range(n):\n",
        "        # initial setup\n",
        "        listActivatedSources = []\n",
        "        listScenarioDataframes = []\n",
        "        condition = True\n",
        "        time = 0 \n",
        "        # wind conditions\n",
        "        w_bearing_max, w_bearing_min, w_distance = wind_scenario(wind_data)\n",
        "        # ignition / initial state and edges selection\n",
        "        ActiveEdges = ignition()\n",
        "        if ActiveEdges.empty:\n",
        "            continue\n",
        "        while condition: # spread burn zone\n",
        "            ActiveEdges = mask(time, ActiveEdges, listActivatedSources, w_bearing_max, w_bearing_min, w_distance)\n",
        "            if ActiveEdges.empty: #no more buildings to burn\n",
        "                break\n",
        "            listScenarioDataframes.append(ActiveEdges)\n",
        "            listActivatedSources.extend(ActiveEdges.source.values)\n",
        "            ActiveEdges = propagation(ActiveEdges)\n",
        "            time += 1\n",
        "        \n",
        "        print(f'finishing pid {os.getpid()} scenario --- {scenario} time ---- {time}')\n",
        "\n",
        "        Activations = pd.concat(listScenarioDataframes)\n",
        "        Activations[\"scenario\"] = scenario\n",
        "        Activations[\"pid\"] = os.getpid()\n",
        "        Activations.to_parquet(str(folder) + '/' + f'scenario{scenario}_pid{os.getpid()}.parquet', engine='auto', compression=\"GZIP\")\n",
        "        "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-b2fc6dd7b88c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    **Definitions**\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9Vq0cczZSy4",
        "colab_type": "text"
      },
      "source": [
        "**Main**\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnDhYvazIOG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run process on all available cores - need to input number of scenarios required\n",
        "# %%time\n",
        "scenario_needed = 3000\n",
        "listPool = [int(scenario_needed/mp.cpu_count())] * mp.cpu_count() # to avoid RAM overload on CPU\n",
        "\n",
        "print(f'{mp.cpu_count()} cores for {sum(listPool)} scenarios')\n",
        "print(f'{len(listPool)} processes (pid) with {listPool[0]} scenarios each')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkBSXLEAzYjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "listPool"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdrtScXZhwdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum(listPool)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhTI5_jgykqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# multiprocessing\n",
        "n_scenario = [2] * mp.cpu_count()\n",
        "p = mp.Pool()\n",
        "results = p.map(ffe_runs, listPool)\n",
        "print(\"Complete\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydETTY_fZB3Q",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Backup**\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSpb6R4lX5-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir(folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOHXu6ShOQJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clean_up('/content/drive/My Drive/Colab Notebooks/02_Output/ffeFinnComparison/scenario*')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wshLyMF0Oyr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pqt = pd.read_parquet(\"/content/drive/My Drive/04_Cloud/01_Work/GNS/008_FFE/runs/output/scenario0_pid1998_Activations.parquet\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyLLVwevIoNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# num_cores = multiprocessing.cpu_count()\n",
        "# print(num_cores)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}