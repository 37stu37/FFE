{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FFEpostprocessing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPlXZqCf+Z+quf+QoS/j2sf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/37stu37/FFE/blob/master/FFEpostprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GscCSHXuz1EQ",
        "colab_type": "text"
      },
      "source": [
        "**pip**\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cUU_cV1z4_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "%%capture\n",
        "!apt update\n",
        "!apt upgrade\n",
        "!apt install gdal-bin python-gdal python3-gdal\n",
        "# Install rtree - Geopandas requirment\n",
        "!apt install python3-rtree\n",
        "# Install Geopandas\n",
        "!pip install git+git://github.com/geopandas/geopandas.git\n",
        "# Install descartes - Geopandas requirment\n",
        "!pip install descartes\n",
        "!pip install memory_profiler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zt3Mso3zxUn",
        "colab_type": "text"
      },
      "source": [
        "**import**\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdshhEPMyxVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os\n",
        "from sys import getsizeof\n",
        "\n",
        "import dask.dataframe as dd\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "from dask.distributed import Client\n",
        "from shapely.geometry import box"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C011k0YnzPIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "client = Client(processes=False)\n",
        "client"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBWDvLkMzRmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_output = '/Volumes/NO NAME'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJMszJtPznf-",
        "colab_type": "text"
      },
      "source": [
        "**definitions**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdhDOrGtzTra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@dask.delayed\n",
        "def read_and_concatenate_parquets(prefix, path=path_output):\n",
        "  L = []\n",
        "  files = glob.glob(os.path.join(path_output, 'output', prefix))# output_scenario_0_step_0.parquet\n",
        "  for file in files:\n",
        "    print(\"file loaded : {}\".format(file))\n",
        "    pqt = dd.read_parquet(file)\n",
        "    L.append(pqt)\n",
        "  df = dd.concat(L)\n",
        "  return df\n",
        "\n",
        "def count_fid_occurences(df):\n",
        "  count = df['source'].value_counts().compute()\n",
        "  count_df = pd.DataFrame({'source': count.index, 'count': count.values})\n",
        "  return count_df\n",
        "\n",
        "def load_shapefile(file_name, minx, miny, maxx, maxy):\n",
        "    # crop data\n",
        "    bbox = box(minx, miny, maxx, maxy)\n",
        "    # building point dataset\n",
        "    gdf_buildings = gpd.read_file(os.path.join('shapefile',file_name), bbox=bbox)\n",
        "    max_extent = gdf_buildings.total_bounds\n",
        "    data_size = getsizeof(gdf_buildings) /(1024.0**3)\n",
        "    print(\"Shapefile extent : {}\".format(max_extent))\n",
        "    print(\"Asset loaded : {}\".format(len(gdf_buildings)))\n",
        "    gdf_buildings.plot(column='IgnProb_bl', cmap='hsv', legend=True)\n",
        "    return gdf_buildings\n",
        "\n",
        "def merge_coordinates_export_shape(ddf, gdf, name_output):\n",
        "  gdf = gdf[['TARGET_FID', 'geometry']]\n",
        "  df = pd.DataFrame(gdf)\n",
        "  # ddf = ddf.compute()\n",
        "  df_merge = ddf.merge(df, how='left', left_on='source', right_on='TARGET_FID')\n",
        "  gdf_merge = gpd.GeoDataFrame(df_merge, geometry='geometry')\n",
        "  gdf_merge.plot(column='count', cmap='seismic', legend=True)\n",
        "  gdf_merge.to_file(os.path.join(path_output, \"results\", name_output + \".shp\"))\n",
        "  return gdf_merge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDxnRocLzkuM",
        "colab_type": "text"
      },
      "source": [
        "**runs**\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pz3M0rmzcmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = read_and_concatenate_parquets(\"scenario*\")\n",
        "count_df = count_fid_occurences(df)\n",
        "\n",
        "gdf = load_shapefile(\"buildings_raw.shp\", 1740508, 5420049, 1755776, 5443033) # whole\n",
        "gdf_count = merge_coordinates_export_shape(count_df, gdf, \"burned_buildings\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}