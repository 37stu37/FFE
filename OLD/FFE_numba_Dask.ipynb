{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/37stu37/FFE/blob/master/FFE_network_one_file_run.ipynb",
      "authorship_tag": "ABX9TyP8Ef//mqZuCE6n1m7gGGAt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/37stu37/FFE/blob/master/FFE_numba_Dask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGCGL2eCzyEv",
        "colab_type": "code",
        "outputId": "33bbcc3e-d47e-4502-fcb3-ca96622ea2aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time \n",
        "%%capture\n",
        "!apt update\n",
        "!apt upgrade\n",
        "!apt install gdal-bin python-gdal python3-gdal \n",
        "# Install rtree - Geopandas requirment\n",
        "!apt install python3-rtree \n",
        "# Install Geopandas\n",
        "!pip install git+git://github.com/geopandas/geopandas.git\n",
        "# Install descartes - Geopandas requirment\n",
        "!pip install descartes \n",
        "!pip install memory_profiler"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.95 s, sys: 663 ms, total: 3.62 s\n",
            "Wall time: 26.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PipQ4HNTjKW",
        "colab_type": "code",
        "outputId": "83e9417e-98ee-452f-ec3e-863643db4fd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "%tensorflow_version 2.x\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr0PZxCvmWCl",
        "colab_type": "code",
        "outputId": "c7dc9c4c-83ec-400a-b446-390b0772811d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%%time\n",
        "import datetime\n",
        "import glob\n",
        "from math import sqrt\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import bokeh\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from scipy.spatial import distance\n",
        "from shapely.geometry import box\n",
        "from shapely.geometry import shape\n",
        "from shapely.geometry import Point\n",
        "import networkx as nx\n",
        "from sys import getsizeof\n",
        "from numba import jit\n",
        "import dask.dataframe as dd\n",
        "import dask.array as da\n",
        "import dask\n",
        "from dask.distributed import Client\n",
        "from dask.diagnostics import ProgressBar\n",
        "%matplotlib inline\n",
        "%load_ext memory_profiler\n",
        "\n",
        "pd.options.mode.chained_assignment = None  # default='warn'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The memory_profiler extension is already loaded. To reload it, use:\n",
            "  %reload_ext memory_profiler\n",
            "CPU times: user 44.7 ms, sys: 4.13 ms, total: 48.8 ms\n",
            "Wall time: 47.6 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz4lyV9f3Sny",
        "colab_type": "code",
        "outputId": "0136914b-929f-465e-ebc9-d40f09b8aa0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "source": [
        "client = Client(processes=False)\n",
        "client"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/distributed/bokeh/core.py:57: UserWarning: \n",
            "Failed to start diagnostics server on port 8787. [Errno 99] Cannot assign requested address\n",
            "  warnings.warn('\\n' + msg)\n",
            "/usr/local/lib/python3.6/dist-packages/distributed/deploy/local.py:197: UserWarning: \n",
            "Could not launch service 'bokeh' on port 8787. Got the following message:\n",
            "\n",
            "[Errno 99] Cannot assign requested address\n",
            "  self.scheduler.start(scheduler_address)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table style=\"border: 2px solid white;\">\n",
              "<tr>\n",
              "<td style=\"vertical-align: top; border: 0px solid white\">\n",
              "<h3>Client</h3>\n",
              "<ul>\n",
              "  <li><b>Scheduler: </b>inproc://172.28.0.2/143/28\n",
              "</ul>\n",
              "</td>\n",
              "<td style=\"vertical-align: top; border: 0px solid white\">\n",
              "<h3>Cluster</h3>\n",
              "<ul>\n",
              "  <li><b>Workers: </b>1</li>\n",
              "  <li><b>Cores: </b>4</li>\n",
              "  <li><b>Memory: </b>27.40 GB</li>\n",
              "</ul>\n",
              "</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<Client: scheduler='inproc://172.28.0.2/143/28' processes=1 cores=4>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2tMnwAEmqpF",
        "colab_type": "text"
      },
      "source": [
        "Set up the path  to data and output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-tLiFKrmZDM",
        "colab_type": "code",
        "outputId": "c90d30a7-89be-4908-fb01-b2e3bd70f84d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "path = '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_input'\n",
        "path_output = '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output'\n",
        "\n",
        "!ls \"/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_input\"\n",
        "!ls '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output/dask_edge_list'\n",
        "# !ls '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "buildings_raw.cpg\tbuildings_raw_pts.shx\n",
            "buildings_raw.dbf\tbuildings_raw.qpj\n",
            "buildings_raw.prj\tbuildings_raw.shp\n",
            "buildings_raw_pts.cpg\tbuildings_raw.shx\n",
            "buildings_raw_pts.dbf\tGD_wind.csv\n",
            "buildings_raw_pts.mshp\toutputs_centroids_allpga_1000GMFs\n",
            "buildings_raw_pts.prj\toutputs_centroids_allpga_1000GMFsPERCENTILES\n",
            "buildings_raw_pts.shp\tsource_target.csv\n",
            "edge_data.parquet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6kl25fSmjGN",
        "colab_type": "text"
      },
      "source": [
        "**Functions**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2p6Jyt2zj0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_up_file(path, prefix):\n",
        "    files = glob.glob(os.path.join(path, prefix))\n",
        "    for file in files:\n",
        "      try:\n",
        "        shutil.rmtree(file)\n",
        "      except:\n",
        "        os.remove(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9H08CSY1fhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wind scenario\n",
        "def wind_scenario(file_name):\n",
        "    # wind scenario conditions\n",
        "    wind_data = pd.read_csv(os.path.join(path, file_name))\n",
        "    i = np.random.randint(0, wind_data.shape[0])\n",
        "    w = wind_data.iloc[i, 2]\n",
        "    d = wind_data.iloc[i, 1]\n",
        "    b = wind_data.iloc[i, 3]\n",
        "    # wind direction\n",
        "    wind_bearing_max = b + 45\n",
        "    wind_bearing_min = b - 45\n",
        "    if b == 360:\n",
        "        wind_bearing_max = 45\n",
        "    if b <= 0:  # should not be necessary\n",
        "        wind_bearing_min = 0\n",
        "    if b == 999:\n",
        "        wind_bearing_max = 999\n",
        "        wind_bearing_min = 0\n",
        "    \n",
        "    return wind_bearing_max, wind_bearing_min, d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIjsYRaVMvp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create ignitions\n",
        "def ignitions(edges, scenario):\n",
        "    # add random column\n",
        "    edges['rng'] = np.random.uniform(0, 1, size=len(edges))\n",
        "    # filter on random column\n",
        "    fires = edges[edges.rng < edges.IgnProb_bl]\n",
        "\n",
        "    fires['step'] = 0\n",
        "    fires['scenario'] = scenario\n",
        "\n",
        "    return fires"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMwRlajrMvoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# conditions of fire propagation\n",
        "def conditions_spread(fires,burn,wind_bearing_max,wind_bearing_min,wind_distance,\n",
        "                      scenario, step):\n",
        "    # add columns to ddf\n",
        "    fires['wind_bearing_max'] = wind_bearing_max\n",
        "    fires['wind_bearing_min'] = wind_bearing_min\n",
        "    fires['wind_distance'] = wind_distance\n",
        "    # wind speed -> neighbors selection from wind buffer\n",
        "    new_fires = fires[fires.distance < fires.wind_distance]\n",
        "    # wind direction\n",
        "    new_fires = new_fires[(new_fires.bearing < new_fires.wind_bearing_max) & (new_fires.bearing < new_fires.wind_bearing_min)]\n",
        "    # should not be already burnt\n",
        "    new_fires = new_fires[~new_fires.target.isin(burn)]\n",
        "\n",
        "    # add columns\n",
        "    new_fires['step'] = step\n",
        "    new_fires['scenario'] = scenario\n",
        "\n",
        "    # log burnt assets\n",
        "    burn.extend(fires.source)\n",
        "    # remove duplicates from burn list\n",
        "    burn = list(set(burn))\n",
        "\n",
        "    # export active fire to parquet for record\n",
        "    fires.to_parquet(os.path.join(path_output, \n",
        "                                   'output_scenario_{}_step_{}.parquet'.format(scenario, step)), engine='pyarrow')\n",
        "    \n",
        "    return new_fires, burn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM3CVlxYMvmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spreading fire\n",
        "def new_fires(fires, edges):\n",
        "  fires_list = list(set(fires.target))\n",
        "  new_fires = edges[edges.source.isin(fires_list)]\n",
        "  return new_fires"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x38ekV6Tfp4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# log burned assets\n",
        "@dask.delayed\n",
        "def record_burnt_assets_for_scenario(scenario):\n",
        "  L = []\n",
        "  files = glob.glob(os.path.join(path_output, \"*output_scenario_{}*\".format(scenario)))\n",
        "  for file in files:\n",
        "    pqt = dd.read_parquet(file)\n",
        "    L.append(pqt)\n",
        "  df = dd.concat(L)\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDoaZtl4IP2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_fid_occurences(df, scenario):\n",
        "  count = df.source.value_counts().compute()\n",
        "  count_df = count.to_frame()\n",
        "  count_df['count'] = count\n",
        "  count_df['source'] = count_df.index\n",
        "  count_df['scenario'] = scenario\n",
        "  count_df = count_df.reset_index()\n",
        "  count_df = count_df.drop(columns='index')\n",
        "  count_df.to_parquet(os.path.join(path_output, \n",
        "                                   'output_scenario_{}.parquet'.format(scenario)), engine='pyarrow')\n",
        "  return print('output_scenario_{}.parquet created'.format(scenario))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulo9yu2MaP-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display network\n",
        "def display_network(edge_list_dataframe):\n",
        "    graph = nx.from_pandas_edgelist(edge_list_dataframe, edge_attr=True)\n",
        "    options = {'node_color': 'red', 'node_size': 50, 'width': 1, 'alpha': 0.4,\n",
        "               'with_labels': False, 'font_weight': 'bold'}\n",
        "    nx.draw_kamada_kawai(graph, **options)\n",
        "    plt.show()\n",
        "    return graph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa9nJc2nMvi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run main\n",
        "def main(number_of_scenarios, edges):\n",
        "  # --- SCENARIOS\n",
        "  print(\"number of scenarios : {}\".format(number_of_scenarios))\n",
        "  for scenario in range(number_of_scenarios):\n",
        "      list_BURNED = []\n",
        "      BURNED = [] # pd.DataFrame(columns=['source','target','distance', 'bearing',\n",
        "                                      # 'IgnProb_bl', 'scenario', 'step'])\n",
        "      # print(\"--- SCENARIO : {}\".format(scenario))\n",
        "      FIRES = ignitions(EDGES, scenario)\n",
        "      if len(FIRES) == 0:\n",
        "          # print(\"no fire\")\n",
        "          continue\n",
        "      wind_bearing_max, wind_bearing_min, wind_distance = wind_scenario('GD_wind.csv') # no filtering, just adding wind info to dataframe\n",
        "      # --------- STEPS\n",
        "      for step in range(len(EDGES)):\n",
        "          # print(\"--------- STEP : {}\".format(step))\n",
        "          FIRES, BURNED = conditions_spread(FIRES, BURNED, wind_bearing_max, wind_bearing_min, wind_distance,scenario, step) # filtering\n",
        "          # list_BURNED.append(BURNED)\n",
        "          if len(FIRES) == 0:\n",
        "            # print(\"no more fire\")\n",
        "            break\n",
        "          FIRES = new_fires(FIRES, edges)\n",
        "\n",
        "      record = record_burnt_assets_for_scenario(scenario)\n",
        "      count_fid_occurences(record, scenario)\n",
        "      clean_up_file(path_output, \"*_step_*\")\n",
        "\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcnbVvdTH22W",
        "colab_type": "text"
      },
      "source": [
        "**Clean up directories and load data**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZwNZ3Vrzzc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_up_file(path_output, \"output*\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0oZS_vBsODJ",
        "colab_type": "code",
        "outputId": "a83e7451-8cf2-4a25-a9da-a53465b4f7cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dask_edge_list\tshapefiles\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXDI561DMvg0",
        "colab_type": "code",
        "outputId": "8f6a0557-bfce-42fd-da07-df55b845f149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%%time\n",
        "%memit\n",
        "# load data\n",
        "# EDGES = dd.read_parquet(os.path.join(path_output, 'dask_edge_list', 'edge_data.parquet'), engine='pyarrow')\n",
        "EDGES = pd.read_parquet(os.path.join(path_output, 'dask_edge_list', 'edge_data.parquet'), engine='pyarrow')\n",
        "print(\"number of edges : {}\".format(len(EDGES)))\n",
        "# G = display_network(EDGES)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "peak memory: 1873.41 MiB, increment: 0.00 MiB\n",
            "number of edges : 3457222\n",
            "CPU times: user 1.07 s, sys: 483 ms, total: 1.55 s\n",
            "Wall time: 1.42 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-_LNjHFIBga",
        "colab_type": "text"
      },
      "source": [
        "**Run the algorithm**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_1D-wW9Mvfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "%memit\n",
        "# run main\n",
        "main(1001, EDGES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5qhwhR9ILWd",
        "colab_type": "text"
      },
      "source": [
        "**Manage output and postprocessing**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bHxeQYlpbuSw",
        "colab": {}
      },
      "source": [
        "# remove parquet_file\n",
        "# clean_up_file(path_output, \"output*\")\n",
        "# !ls '/content/drive/My Drive/05_Sync/FFE/FireNetwork/00_output'"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}