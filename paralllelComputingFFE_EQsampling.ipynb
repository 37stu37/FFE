{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": "true",
    "id": "m42Qt2fkaDi8"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T03:44:44.255464Z",
     "start_time": "2020-09-02T03:44:44.250594Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T03:47:35.434425Z",
     "start_time": "2020-09-02T03:47:35.428660Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "7O35x2t8T4Dk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import geopandas as gpd\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import multiprocessing as mp\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T03:47:56.187322Z",
     "start_time": "2020-09-02T03:47:56.174246Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "QtfIG4oqTqPD",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 0 ns\n"
    }
   ],
   "source": [
    "%%time\n",
    "# Folders\n",
    "repository = Path.cwd()\n",
    "dataFolder = repository.parent.parent / 'InOutRepoData' / 'FFE'\n",
    "folder = dataFolder / 'ProbaScenarioOutput'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 6.68 s\n"
    }
   ],
   "source": [
    "%%time\n",
    "# Data\n",
    "\n",
    "wind_data = pd.read_csv(repository / 'data' / 'Copy_of_GD_wind.csv')\n",
    "building_data = gpd.read_file(repository / 'data' / 'shapefile' / 'BuildingFootprints.shp')\n",
    "building_data = dd.from_pandas(building_data.drop(columns=['geometry']), npartitions=1)\n",
    "edgelist = pd.read_parquet(repository / 'data' / 'Copy_of_edge_data.parquet', engine='pyarrow')\n",
    "edgelist.drop(columns=['IgnProb_bl'], inplace=True)\n",
    "earthquake_events = dd.read_parquet(dataFolder / 'ProbaScenariosInput' / 'joinSA_PGA.parquet', engine='pyarrow')\n",
    "earthquake_events = earthquake_events.drop(columns=['__null_das'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dask DataFrame Structure:\n              event_id site_id SA2_ID  gmv_PGA      lon      lat  IgnProb\nnpartitions=1                                                            \n                 int64   int64  int64  float64  float64  float64  float64\n                   ...     ...    ...      ...      ...      ...      ...\nDask Name: getitem, 5 tasks\nDask DataFrame Structure:\n              OBJECTID Replacemen Combustibl FloorArea BLDG_ID Shape_Leng Shape_Area SA2_ID NightOccup event_id site_id  gmv_PGA      lon      lat  IgnProb\nnpartitions=1                                                                                                                                              \n               float64    float64      int64   float64   int64    float64    float64  int64    float64    int64   int64  float64  float64  float64  float64\n                   ...        ...        ...       ...     ...        ...        ...    ...        ...      ...     ...      ...      ...      ...      ...\nDask Name: merge, 7 tasks\n"
    }
   ],
   "source": [
    "EQs = earthquake_events\n",
    "buildings = building_data\n",
    "EQ = EQs[EQs['event_id']==EventNumber]\n",
    "print(EQ)\n",
    "buildingEQ = buildings.merge(EQ, on=['SA2_ID'], how='left')\n",
    "print(buildingEQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "141569"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "EventNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'randint'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-4bf1c4642385>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# EventNumber = np.randint(0,max(EQs['event_id'])) # use range of OpenQuake events\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mEQ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEQs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mEQs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'event_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mEventNumber\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbuildingEQ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuildings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SA2_ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mbuildingEQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'source'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'gmv_PGA'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'IgnProb'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# former RNGfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'randint'"
     ]
    }
   ],
   "source": [
    "# EventNumber = np.randint(0,max(EQs['event_id'])) # use range of OpenQuake events\n",
    "np.randint(0,10)\n",
    "EQ = EQs[EQs['event_id']==EventNumber].compute()\n",
    "buildingEQ = buildings.merge(EQ, on=['SA2_ID'], how='left')\n",
    "return buildingEQ[['source','gmv_PGA','IgnProb']] # former RNGfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### **Method : PGA_SA join --> pick 1 EQ event --> Attach Ignition Probability to buildings --> Run Fire scenario**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "## Parallel computing set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DirectView [0, 1, 2, 3,...]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipyparallel as ipp\n",
    "client = ipp.Client()\n",
    "dview = client[:]# limit to 10 cores for now\n",
    "client.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     9
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing numpy on engine(s)\n",
      "importing pandas on engine(s)\n",
      "importing Path from pathlib on engine(s)\n",
      "importing sys on engine(s)\n",
      "importing os on engine(s)\n",
      "importing glob on engine(s)\n",
      "importing date from datetime on engine(s)\n"
     ]
    }
   ],
   "source": [
    "# add variables to all engines\n",
    "dview[\"edgelist\"]=edgelist\n",
    "dview[\"buildings\"]=building_data\n",
    "dview[\"wind_data\"]=wind_data\n",
    "dview[\"folder\"]=folder\n",
    "dview[\"earthquake_events\"]=earthquake_events\n",
    "\n",
    "\n",
    "# add all libraries to engines\n",
    "with dview.sync_imports():\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import dask.dataframe as dd\n",
    "    import geopandas as gpd\n",
    "    from pathlib import Path\n",
    "    import sys\n",
    "    import os\n",
    "    import glob\n",
    "    from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     2,
     20,
     33,
     43,
     54
    ],
    "colab": {},
    "colab_type": "code",
    "id": "Q7pHNrjZN8Zw"
   },
   "outputs": [],
   "source": [
    "# %%px\n",
    "\n",
    "def wind_scenario(wind_data):\n",
    "    import numpy as np\n",
    "    i = np.random.randint(0, wind_data.values.shape[0])\n",
    "    w = wind_data.values[i, 2]\n",
    "    dist = wind_data.values[i, 1]\n",
    "    b = wind_data.values[i, 3]\n",
    "    bear_max = b + 45  # wind direction\n",
    "    bear_min = b - 45\n",
    "    if b == 360:\n",
    "        bear_max = 45\n",
    "    if b <= 0:  # should not be necessary\n",
    "        bear_min = 0\n",
    "    if b == 999:\n",
    "        bear_max = 999\n",
    "        bear_min = 0\n",
    "    return bear_max, bear_min, dist # wind characteristics, bearing and distance\n",
    "\n",
    "\n",
    "def earthquake_scenario(EQs=earthquake_events, buildings=building_data):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import dask.dataframe as dd\n",
    "\n",
    "    EventNumber = np.random.randint(0,max(EQs['event_id'])) # use range of OpenQuake events\n",
    "    EQ = EQs[EQs['event_id']==EventNumber]\n",
    "    buildingEQ = buildings.merge(EQ, on=['SA2_ID'], how='left')\n",
    "    return buildingEQ[['source','gmv_PGA','IgnProb']] # former RNGfile\n",
    "\n",
    "\n",
    "def ignition(rngFile, edges=edgelist):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    rngList = rngFile[['source', 'IgnProb']]\n",
    "    rngList = rngList.drop_duplicates(columns=['source']).compute()\n",
    "\n",
    "    rngList['rng'] = np.random.uniform(0, 1, size=rngList.values.shape[0])\n",
    "    rngList = rngList[rngList['rng'] < rngList['IgnProb']]\n",
    "    initialIgnitions = len(rngList)\n",
    "    NewActiveEdges = edges[edges['source'].isin(rngList['source'])]\n",
    "    return NewActiveEdges, initialIgnitions\n",
    "\n",
    "\n",
    "def mask(t, activeEdges_d, listActivatedSources_d, w_b_max, w_b_min, w_d):\n",
    "    import numpy as np\n",
    "    if t==0: # special case at time=0\n",
    "        return activeEdges_d\n",
    "    else:\n",
    "        mask = (activeEdges_d.bearing.values < w_b_max) & (activeEdges_d.bearing.values < w_b_min) & (activeEdges_d.distance < w_d)\n",
    "        NewActiveEdges = activeEdges_d[mask]\n",
    "        NewActiveEdges = NewActiveEdges[~NewActiveEdges.source.isin(listActivatedSources_d)]\n",
    "        return NewActiveEdges\n",
    "\n",
    "\n",
    "def propagation(activeEdges_d, edges=edgelist):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    NewActiveEdges = edges[edges.source.isin(activeEdges_d.target)]\n",
    "    return NewActiveEdges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "@dview.parallel(block = False) # The @parallel decorator breaks up elementwise operations and distributes them.\n",
    "def EQffe_runs(n):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from datetime import date\n",
    "    for EQFFEscenario in n:\n",
    "        EQscenario = earthquake_scenario()\n",
    "        # initial setup\n",
    "        listActivatedSources = []\n",
    "        listScenarioDataframes = []\n",
    "        condition = True\n",
    "        time = 0 \n",
    "        # wind conditions\n",
    "        w_bearing_max, w_bearing_min, w_distance = wind_scenario(wind_data)\n",
    "        # ignition / initial state and edges selection\n",
    "        ActiveEdges, numberIgnitions = ignition(EQscenario)\n",
    "        if ActiveEdges.empty:\n",
    "            print(f\"no ignitions {numberIgnitions}\")\n",
    "            condition = False\n",
    "            continue\n",
    "        while condition: # spread burn zone\n",
    "            ActiveEdges = mask(time, ActiveEdges, listActivatedSources, w_bearing_max, w_bearing_min, w_distance)\n",
    "            if ActiveEdges.empty: #no more buildings to burn\n",
    "                break\n",
    "            burns = ActiveEdges.drop_duplicates(['source'], inplace=False)\n",
    "#             print(f\"Active edges {len(ActiveEdges)} / no duplicate = {len(burns)}\")\n",
    "            burns['time'] = time\n",
    "            listScenarioDataframes.append(burns)\n",
    "            listActivatedSources.extend(ActiveEdges.source.values)\n",
    "            ActiveEdges = propagation(ActiveEdges)\n",
    "            time += 1\n",
    "        \n",
    "        print(f'finishing scenario --- {EQFFEscenario} time ---- {time} \\n started with {numberIgnitions} ignitions ')\n",
    "\n",
    "        Activations = pd.concat(listScenarioDataframes)\n",
    "        Activations[\"EQFFEscenario\"] = EQFFEscenario\n",
    "        Activations[\"InitialIgnitions\"] = numberIgnitions\n",
    "        Activations.to_parquet(str(folder) + '/' + f'scenario{EQFFEscenario}_{str(date.today())}.parquet', engine='auto', compression=\"GZIP\")\n",
    "        # save parameters behind the scenario\n",
    "        parameters = {'building_id':EQscenario['source'].values,\n",
    "                      'gmf_PGA':EQscenario['gmf_PGA'].values,\n",
    "                      'IgnProb':EQscenario['IgnProb'].values,\n",
    "                      'Wind bearing max': np.repeat(w_bearing_max.values, len(EQscenario)),\n",
    "                      'Wind bearing min': np.repeat(w_bearing_min.values, len(EQscenario)),\n",
    "                     'Wind distance': np.repeat(w_distance.values, len(EQscenario)}\n",
    "        df_parameters = pd.Dataframe(parameters, columns=['building_id','gmf_PGA',\n",
    "                                                          'IgnProb','Wind bearing max',\n",
    "                                                          'Wind bearing min','Wind distance'])\n",
    "        df_parameters.to_csv(str(folder) + '/' + f'parameters{EQFFEscenario}_{str(date.today())}.csv)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": "true",
    "id": "g9Vq0cczZSy4"
   },
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AsyncMapResult: ffe_runs>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "EQffe_runs(range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ydETTY_fZB3Q"
   },
   "source": [
    "\n",
    "### Backup and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>distance</th>\n",
       "      <th>bearing</th>\n",
       "      <th>IgnProbBld</th>\n",
       "      <th>time</th>\n",
       "      <th>scenario</th>\n",
       "      <th>InitialIgnitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>58927</td>\n",
       "      <td>1339</td>\n",
       "      <td>7165</td>\n",
       "      <td>85.191863</td>\n",
       "      <td>254.643103</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177754</td>\n",
       "      <td>4087</td>\n",
       "      <td>1171</td>\n",
       "      <td>42.839607</td>\n",
       "      <td>146.200091</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1553230</td>\n",
       "      <td>36012</td>\n",
       "      <td>20709</td>\n",
       "      <td>46.135131</td>\n",
       "      <td>327.995628</td>\n",
       "      <td>0.005239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1838643</td>\n",
       "      <td>42567</td>\n",
       "      <td>819</td>\n",
       "      <td>61.723592</td>\n",
       "      <td>176.924230</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1870466</td>\n",
       "      <td>43322</td>\n",
       "      <td>69</td>\n",
       "      <td>18.925020</td>\n",
       "      <td>224.543699</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2437404</td>\n",
       "      <td>56553</td>\n",
       "      <td>2724</td>\n",
       "      <td>79.663636</td>\n",
       "      <td>261.571453</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500477</td>\n",
       "      <td>58033</td>\n",
       "      <td>38</td>\n",
       "      <td>73.423960</td>\n",
       "      <td>28.218908</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3072849</td>\n",
       "      <td>71356</td>\n",
       "      <td>513</td>\n",
       "      <td>65.566426</td>\n",
       "      <td>303.012553</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         source  target   distance     bearing  IgnProbBld  time  scenario  \\\n",
       "58927      1339    7165  85.191863  254.643103    0.000073     0         0   \n",
       "177754     4087    1171  42.839607  146.200091    0.000068     0         0   \n",
       "1553230   36012   20709  46.135131  327.995628    0.005239     0         0   \n",
       "1838643   42567     819  61.723592  176.924230    0.000288     0         0   \n",
       "1870466   43322      69  18.925020  224.543699    0.000253     0         0   \n",
       "2437404   56553    2724  79.663636  261.571453    0.000117     0         0   \n",
       "2500477   58033      38  73.423960   28.218908    0.000313     0         0   \n",
       "3072849   71356     513  65.566426  303.012553    0.000213     0         0   \n",
       "\n",
       "         InitialIgnitions  \n",
       "58927                   8  \n",
       "177754                  8  \n",
       "1553230                 8  \n",
       "1838643                 8  \n",
       "1870466                 8  \n",
       "2437404                 8  \n",
       "2500477                 8  \n",
       "3072849                 8  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_parquet(folder / 'scenario0_2020-08-06.parquet')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_up(path=folder):\n",
    "#     files = path.glob('*scenario*')\n",
    "#     for f in files:\n",
    "#         print(f)\n",
    "#         os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOHXu6ShOQJU"
   },
   "outputs": [],
   "source": [
    "# clean_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "FFErunsParallel.ipynb",
   "provenance": []
  },
  "gist": {
   "data": {
    "description": "paralllelComputingFFE_EQsampling.ipynb",
    "public": true
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.716px",
    "left": "774.812px",
    "right": "20px",
    "top": "122.991px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}