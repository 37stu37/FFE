{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/37stu37/FFE/blob/master/FFE_network_one_file_run.ipynb",
      "authorship_tag": "ABX9TyPmT0V6gxqSekQpAsa4tOFh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/37stu37/FFE/blob/master/FFE_network_one_file_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGCGL2eCzyEv",
        "colab_type": "code",
        "outputId": "16d92b81-adcd-448f-eba3-e6787dbe0fb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time \n",
        "%%capture\n",
        "!apt update\n",
        "!apt upgrade\n",
        "!apt install gdal-bin python-gdal python3-gdal \n",
        "# Install rtree - Geopandas requirment\n",
        "!apt install python3-rtree \n",
        "# Install Geopandas\n",
        "!pip install git+git://github.com/geopandas/geopandas.git\n",
        "# Install descartes - Geopandas requirment\n",
        "!pip install descartes "
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 329 ms, sys: 73.5 ms, total: 402 ms\n",
            "Wall time: 46 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PipQ4HNTjKW",
        "colab_type": "code",
        "outputId": "91450f1b-acb6-4f18-fdb2-7476cd80f435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "%tensorflow_version 2.x\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "# pip freeze --local > /content/gdrive/My\\ Drive/Colab Notebooks/pip_installed.txt"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr0PZxCvmWCl",
        "colab_type": "code",
        "outputId": "6e2e939d-dded-4c3d-fe63-a891e0367064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "import datetime\n",
        "import glob\n",
        "import math\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import box\n",
        "import networkx as nx\n",
        "from shapely.geometry import Point\n",
        "import imageio\n",
        "\n",
        "pd.options.mode.chained_assignment = None  # default='warn'"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 141 µs, sys: 0 ns, total: 141 µs\n",
            "Wall time: 160 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2tMnwAEmqpF",
        "colab_type": "text"
      },
      "source": [
        "Set up the path  to data and output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-tLiFKrmZDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/05_Sync/FFE/Mesa'\n",
        "path_output = '/content/drive/My Drive/05_Sync/FFE/Mesa/output'\n",
        "\n",
        "# !ls \"/content/drive/My Drive/05_Sync/FFE/Mesa\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6kl25fSmjGN",
        "colab_type": "text"
      },
      "source": [
        "Create the functions to be used by the algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PZosFepFncaX",
        "colab": {}
      },
      "source": [
        "def load_data(file_name, minx, miny, maxx, maxy):\n",
        "    # crop data\n",
        "    bbox = box(minx, miny, maxx, maxy)\n",
        "    # building point dataset\n",
        "    gdf_buildings = gpd.read_file(os.path.join(path, file_name), bbox=bbox)\n",
        "    # gdf_buildings.IgnProb_bl = 0.02\n",
        "    # xmin,ymin,xmax,ymax = gdf_buildings.total_bounds\n",
        "    return gdf_buildings\n",
        "\n",
        "\n",
        "def wind_scenario():\n",
        "    wind_data = pd.read_csv(os.path.join(path, 'GD_wind.csv'))\n",
        "    i = np.random.randint(0, wind_data.shape[0])\n",
        "    w = wind_data.iloc[i, 2]\n",
        "    d = wind_data.iloc[i, 1]\n",
        "    b = wind_data.iloc[i, 3]\n",
        "    return w, d, b\n",
        "\n",
        "\n",
        "def create_network(edge_list_dataframe):\n",
        "    graph = nx.from_pandas_edgelist(edge_list_dataframe, edge_attr=True)\n",
        "    # options = {'node_color': 'red', 'node_size': 50, 'width': 1, 'alpha': 0.4,\n",
        "    #            'with_labels': False, 'font_weight': 'bold'}\n",
        "    # nx.draw_kamada_kawai(graph, **options)\n",
        "    # plt.show()\n",
        "    return graph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjmAYO9UnNOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_initial_fire_to(df):\n",
        "    \"\"\"Fine = 0, Fire = 1, Burned = 2\"\"\"\n",
        "    df['RNG'] = np.random.uniform(0, 1, size=len(df))  # add for random suppression per building, df.shape[0])\n",
        "    onFire = df['source_IgnProb_bl'] > df['RNG']\n",
        "    ignitions = df[onFire]\n",
        "    # source nodes ignited\n",
        "    sources_on_fire = list(ignitions.source)\n",
        "    sources_on_fire = list(dict.fromkeys(sources_on_fire))\n",
        "    return sources_on_fire\n",
        "\n",
        "\n",
        "def set_fire_to(df, existing_fires):\n",
        "    are_set_on_fire = (df['source'].isin(existing_fires))\n",
        "    spark = df[are_set_on_fire]\n",
        "    # source nodes ignited\n",
        "    sources_on_fire = list(spark.source)\n",
        "    sources_on_fire = list(dict.fromkeys(sources_on_fire))\n",
        "    return sources_on_fire\n",
        "\n",
        "\n",
        "def fire_spreading(list_fires, list_burn, wind_speed, wind_bearing, suppression_threshold, step_value, data):\n",
        "    # check the fire potential targets\n",
        "    # print(\"fire list before spreading : {}, length : {}\".format(fire_list, len(fire_list)))\n",
        "    are_potential_targets = (data['source'].isin(list_fires))\n",
        "    are_not_already_burned = (~data['target'].isin(list_burn))\n",
        "    df = data[are_potential_targets & are_not_already_burned]\n",
        "    if df.empty:\n",
        "        # print(\"no fires\")\n",
        "        list_burn.extend(list(list_fires))\n",
        "        list_burn = list(dict.fromkeys(list_burn))\n",
        "        return [], list_burn  # to break the step loop\n",
        "    # set up additional CONDITIONS for fire spreading\n",
        "\n",
        "    # neighbors selection from buffer\n",
        "    df['buffer_geometry'] = gdf.geometry.buffer(gdf['d_long'] + wind_speed)\n",
        "\n",
        "    are_neighbors = df['euc_distance'] < wind_speed\n",
        "    # print(\"neighbors affected ? {}\".format(list(dict.fromkeys(list(are_neighbors)))))\n",
        "    df = df[are_neighbors]\n",
        "    # wind direction\n",
        "    wind_bearing_max = wind_bearing + 45\n",
        "    wind_bearing_min = wind_bearing - 45\n",
        "    if wind_bearing == 360:\n",
        "        wind_bearing_max = 45\n",
        "    if wind_bearing <= 0:  # should not be necessary\n",
        "        wind_bearing_min = 0\n",
        "    if wind_bearing == 999:\n",
        "        wind_bearing_max = 999\n",
        "        wind_bearing_min = 0\n",
        "    are_under_the_wind = (df['bearing'] < wind_bearing_max) & (df['bearing'] > wind_bearing_min)\n",
        "    # print(\"targets under the wind ? {}\".format(list(dict.fromkeys(list(are_under_the_wind)))))\n",
        "    df = df[are_under_the_wind]\n",
        "    # suppression\n",
        "    df['random'] = np.random.uniform(0, 1, size=len(df))\n",
        "    are_not_suppressed = df['random'] > suppression_threshold\n",
        "    # print(\"fire suppressed ? {}\".format(list(dict.fromkeys(list(are_not_suppressed)))))\n",
        "    df = df[are_not_suppressed]\n",
        "\n",
        "    # spread fire based on condition\n",
        "    fire_df = df\n",
        "    # fire_df = df[are_neighbors & are_under_the_wind & are_not_suppressed]  # issues with \"are_under_the_wind\n",
        "    # print(len(fire_df.head(5)))\n",
        "    # print(len(fire_df))\n",
        "    list_burn.extend(list(list_fires))\n",
        "    fire_df['step'] = step_value\n",
        "    fire_df.to_csv(os.path.join(path_output, \"step{}_fire.csv\".format(step_value)))\n",
        "    list_fires = list(dict.fromkeys(list(fire_df.target)))\n",
        "    list_burn.extend(list(fire_df.target))\n",
        "    list_burn = list(dict.fromkeys(list_burn))\n",
        "    return list_fires, list_burn\n",
        "\n",
        "\n",
        "def log_files_concatenate(prefix, scenario_count):\n",
        "    list_df = []\n",
        "    files = glob.glob(os.path.join(path_output, prefix))\n",
        "    if files:\n",
        "        for file in files:\n",
        "            # print(file)\n",
        "            df = pd.read_csv(os.path.join(path_output, file))\n",
        "            list_df.append(df)\n",
        "            os.remove(file)\n",
        "        data = pd.concat(list_df)\n",
        "        data['scenario'] = scenario_count\n",
        "        data.to_csv(os.path.join(path_output, \"fire_scenario_{}.csv\".format(scenario_count)))\n",
        "    else:\n",
        "        print(\"no files to concatenate\")\n",
        "\n",
        "\n",
        "def clean_up_file(prefix, path_path=path_output):\n",
        "    files = glob.glob(os.path.join(path_path, prefix))\n",
        "    for file in files:\n",
        "        # print(file)\n",
        "        os.remove(file)\n",
        "\n",
        "\n",
        "def postprocessing(scenarios_recorded, burned_asset, edge_list, gdf_polygons):\n",
        "    list_of_tuples = list(zip(scenarios_recorded, burned_asset))\n",
        "    df = pd.DataFrame(list_of_tuples, columns=['scenarios', 'burned_asset_index'])\n",
        "    # df['count'] = df['burned_asset_index'].value_counts().values\n",
        "    df['count'] = df.groupby('burned_asset_index')['burned_asset_index'].transform('count')\n",
        "    print(df.describe())\n",
        "    df = df[['burned_asset_index', 'count']].drop_duplicates()\n",
        "    edge = edge_list[\n",
        "        ['source', 'source_TARGET_FID', 'source_X', 'source_Y', 'source_geometry']]\n",
        "    df_id = pd.merge(df, edge, left_on='burned_asset_index', right_on='source', how='left')\n",
        "    # print(list(df_id))\n",
        "    df_count = pd.merge(gdf_polygons, df_id, left_on='TARGET_FID', right_on='source_TARGET_FID', how='outer')\n",
        "    df_count = df_count.drop_duplicates()\n",
        "    dataframe = pd.DataFrame(df_count.drop(columns=['geometry', 'source_geometry']))\n",
        "    dataframe = dataframe.dropna()\n",
        "    fig, ax = plt.subplots(1, 1)\n",
        "    df_count.plot(column='count', cmap='RdYlBu_r', ax=ax, legend=True)\n",
        "    ax.title.set_text(\"Burned buildings after {} scenarios\".format(max(scenarios_recorded)))\n",
        "    plt.savefig(os.path.join(path_output, \"results_{}.png\".format(number_of_scenarios)))\n",
        "    # plt.show()\n",
        "    plt.close(fig)\n",
        "    df_count = df_count.drop(columns=['source', 'source_TARGET_FID', 'source_X', 'source_Y', 'source_geometry'])\n",
        "    df_count.to_csv(os.path.join(path_output, \"results.csv\"))\n",
        "    # df_count.to_file(os.path.join(path_output, \"results.shp\"))\n",
        "    return df_count, dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV7sg0YI8V4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def edge_list_itertuple(geodataframe, maximum_distance):\n",
        "  list_dataframes = []\n",
        "  for row in geodataframe.itertuples():\n",
        "    source_list = [row.TARGET_FID] * len(geodataframe)\n",
        "    source_list = np.hstack(source_list)\n",
        "    target_list = list(geodataframe.TARGET_FID)\n",
        "    frame = { 'source': source_list, 'target': target_list } \n",
        "    df = pd.DataFrame(frame)\n",
        "\n",
        "    # create edgelist geodataframe to calculate distance and bearing\n",
        "    polygons = geodataframe[['TARGET_FID', 'geometry', 'IgnProb_bl']]\n",
        "    in_source_list = polygons['TARGET_FID'].isin(source_list)\n",
        "    polygons_crop = polygons[in_source_list]\n",
        "\n",
        "    # create a df from the source row selected of the length source list\n",
        "    source_df = polygons_crop.append([polygons_crop]*(len(source_list)-1),ignore_index=True)\n",
        "    source_df.rename(columns={'IgnProb_bl': 'source_IgnProb_bl'}, inplace=True)\n",
        "    target_df = polygons.copy()\n",
        "    target_df.rename(columns={'IgnProb_bl': 'target_IgnProb_bl'}, inplace=True)\n",
        "\n",
        "    # convert to geodataframe and calculate centroid X Y \n",
        "    source_gdf = gpd.GeoDataFrame(source_df, geometry='geometry')\n",
        "    target_gdf = gpd.GeoDataFrame(target_df, geometry='geometry')\n",
        "\n",
        "    # calculate vectors between centroids\n",
        "    v1 = source_gdf.centroid.x - target_gdf.centroid.x\n",
        "    v2 = source_gdf.centroid.y - target_gdf.centroid.y\n",
        "    \n",
        "    # calcuate bearings between centroids\n",
        "    df['azimuth'] = np.degrees(np.arctan2(v2, v1))\n",
        "    df['bearing'] = (df['azimuth'] + 360) % 360\n",
        "\n",
        "    # calculate distance\n",
        "    distance_series = source_geometries.distance(target_geometries)\n",
        "    df['distance'] = distance_series\n",
        "\n",
        "    # add ignition probability\n",
        "    df['source_IgnProb_bl'] = source_df['source_IgnProb_bl']\n",
        "    df['target_IgnProb_bl'] = target_df['target_IgnProb_bl']\n",
        "\n",
        "    # filter data based on distance\n",
        "    not_himself = df['distance'] != 0\n",
        "    above_the_threshold = df['distance'] < maximum_distance\n",
        "    df = df[(not_himself) & (above_the_threshold)]\n",
        "\n",
        "    # concatenate dataframes \n",
        "    list_dataframes.append(df)\n",
        "\n",
        "  edge_list = pd.concat(list_dataframes)\n",
        "  return edge_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z4jZW6Z56Ff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7bf96e26-86dd-496b-90ad-8c14ca6eedd7"
      },
      "source": [
        "%%time\n",
        "# create edge list and network\n",
        "edges = edge_list_itertuple(gdf_polygon, 45)\n",
        "\n",
        "# create edges\n",
        "G = create_network(edges)"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 21s, sys: 16.7 ms, total: 1min 21s\n",
            "Wall time: 1min 21s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}